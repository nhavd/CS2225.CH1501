{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LWZwLOITw9Ei",
    "outputId": "bfb0c403-521c-422c-994a-3d19e3f59ca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "!cp './drive/MyDrive/Colab\\ Notebooks/model/ViolenceDetection.h5' /content\n",
    "\n",
    "!cp './drive/MyDrive/Colab\\ Notebooks/demo/mma.mp4' /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "B-Ro88bjLFLS",
    "outputId": "136e5edb-e9a4-442a-dbdf-0de5526eb822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-video in /usr/local/lib/python3.6/dist-packages (1.1.11)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.18.5)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (7.0.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Used Libraries\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import skvideo.io\n",
    "import h5py\n",
    "from google.colab.patches import cv2_imshow\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "#Parameters\n",
    "NUMBER_OF_FRAMES = 20\n",
    "IMAGE_SIZE = 160\n",
    "IMAGE_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lG3_QlbZxCtd"
   },
   "outputs": [],
   "source": [
    "ViolenceDetection = load_model('ViolenceDetection.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mndUzBpNKdi"
   },
   "outputs": [],
   "source": [
    "\n",
    "def autocrop(image, threshold=0):\n",
    "    if len(image.shape) == 3:\n",
    "        flatImage = np.max(image, 2)\n",
    "    else:\n",
    "        flatImage = image\n",
    "    assert len(flatImage.shape) == 2\n",
    "\n",
    "    rows = np.where(np.max(flatImage, 0) > threshold)[0]\n",
    "    if rows.size:\n",
    "        cols = np.where(np.max(flatImage, 1) > threshold)[0]\n",
    "        image = image[cols[0]: cols[-1] + 1, rows[0]: rows[-1] + 1]\n",
    "    else:\n",
    "        image = image[:1, :1]\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-En5vDdKNFtn"
   },
   "outputs": [],
   "source": [
    "def scale_and_resize(image):\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  image = autocrop(image)\n",
    "  image = cv2.resize(image,(IMAGE_SIZE,IMAGE_SIZE))\n",
    "  image = image/255.0\n",
    "  return image.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rl1hVOZVLqAe"
   },
   "outputs": [],
   "source": [
    "def extract_frames(video_name):\n",
    "  output_videos = []\n",
    "\n",
    "  videodata = skvideo.io.vread(video_name)\n",
    "  steps = videodata.shape[0] // NUMBER_OF_FRAMES\n",
    "  new_images = []\n",
    "  scaled_images = []\n",
    "  new_diff = np.zeros((int(NUMBER_OF_FRAMES/2),IMAGE_SIZE,IMAGE_SIZE,IMAGE_CHANNELS))\n",
    "  count = 0\n",
    "\n",
    "  for j in range(NUMBER_OF_FRAMES):\n",
    "      new_images.append(videodata[j*steps])\n",
    "      scaled_images.append(scale_and_resize(videodata[j*steps]))\n",
    "\n",
    "  for j in range(0,NUMBER_OF_FRAMES,2):\n",
    "    new_diff[count] = scale_and_resize(cv2.absdiff(new_images[j],new_images[j+1]))\n",
    "    count += 1 \n",
    "  \n",
    "  output_videos.append(new_diff)\n",
    "  output_videos = np.array(output_videos)\n",
    "  scaled_images = np.array(scaled_images)\n",
    "  return output_videos , scaled_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMfA1n_LQo5I"
   },
   "outputs": [],
   "source": [
    "def Violence_detection(videoname):\n",
    "  vid, img = extract_frames(videoname)\n",
    "\n",
    "  violence_res = ViolenceDetection(vid)\n",
    "  if violence_res > 0.6:\n",
    "    print(\"Violence Detected\")\n",
    "  else:\n",
    "    print(\"No Violence Detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBzuXxgzGZ7K"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Predictor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}